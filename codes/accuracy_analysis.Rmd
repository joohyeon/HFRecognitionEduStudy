---
title: "R Notebook"
output:
 html_document:
 css: "style.css"
editor_options: 
  chunk_output_type: inline
---

```{r message=FALSE}
options(warn=-1)
options(digits=3)

# load packages
library(dplyr)
library(ggplot2)
library(tidyr)
library(reshape2)
```

```{r}
#
# load data - subject responses
#
response = read.csv(file = "./data/subject responses - accuracy analysis.csv", header=TRUE, sep=",")

response$pre_post = factor(response$pre_post, levels=c('pretest','posttest'), labels = c("pretest", "posttest"))
```

## HF recognition accuracy analysis

```{r message=FALSE}
#
# calculate the difference of pre- and post-test accuracy from individuals' responses
#
pre_post_accuracy = response %>% 
  group_by(study_group, pre_post, user_id) %>%
  summarize(mean.score = mean(correct), 
            sd.score = sd(correct),
            n.score = n())

pre_post_accuracy_pvt = pre_post_accuracy %>%
  select(-c(sd.score, n.score)) %>%
  pivot_wider(names_from=pre_post, values_from=mean.score) %>%
  mutate(diff = posttest - pretest)


```

```{r}
# Check normality of the difference in each group 
for (type in unique(pre_post_accuracy_pvt$study_group)) {
  cat(type)
  sub_data = pre_post_accuracy_pvt %>% filter(study_group == type)
  print(shapiro.test(sub_data$diff))
}

```

```{r}
#
#  functions for the lower and upper bounds of confidence interval 
#
lower_ci <- function(mean, se, n, conf_level = 0.95){
  lower_ci <- mean - qt(1 - ((1 - conf_level) / 2), n - 1) * se
}
upper_ci <- function(mean, se, n, conf_level = 0.95){
  upper_ci <- mean + qt(1 - ((1 - conf_level) / 2), n - 1) * se
}
```

```{r}
# unpviot data (tall-skinny shape) 
pre_post_accuracy_unpviot = pre_post_accuracy_pvt %>% 
  melt(, id.vars=c("study_group", "user_id"), 
       measure.vars = c("pretest", "posttest", "diff") )

```

```{r message=FALSE}
#
# The difference in accuracy before and after intervention access
# (Primary outcome in Table 2)
#
pre_post_result = pre_post_accuracy_unpviot %>% 
  group_by(study_group, variable) %>%
  summarize(smean = mean(value), 
            ssd = sd(value),
            n = n()) %>%
  mutate(se = ssd / sqrt(n),
         lower_ci = round(lower_ci(smean, se, n),3),
         upper_ci = round(upper_ci(smean, se, n),3))

pre_post_result
```

```{r}
#
# The paired t-test to measure the significance of the primary outcome
# (p-values in Table 2)
#
options(digits=3)

for (type in unique(pre_post_accuracy_pvt$study_group)) {
  sub_data = pre_post_accuracy_pvt %>% filter(study_group == type)
  mean_post = sub_data$pretest
  mean_pre = sub_data$posttest
  print(type)
  result = t.test(mean_post, mean_pre, paired = TRUE, alternative = "two.sided", d=4)
  print(result)
  print(result[3])
}
  

```


## Accuracy analysis on low and high complexity of preoperative health screening

```{r message=FALSE}
pre_post_lvl_accuracy = response %>%
  group_by(study_group, pre_post, qz_level, user_id) %>%
  summarize(mean.score = mean(correct),
            sd.score = sd(correct),
            n.score = n())

pre_post_lvl_accuracy_pvt = pre_post_lvl_accuracy %>%
  select(-c(sd.score, n.score)) %>%
  pivot_wider(names_from=pre_post, values_from=mean.score) %>%
  mutate(diff = posttest - pretest)


```

```{r}
pre_post_lvl_accuracy_unpviot = pre_post_lvl_accuracy_pvt %>% 
  melt(, id.vars=c("study_group", "qz_level", "user_id"), measure.vars = c("pretest", "posttest", "diff") )

```

```{r message=FALSE}
#
# The difference in accuracy before and after intervention access, 
#   stratified by complexity of preoperative health screening
# (Secondary outcomes in Table 3)
#
pre_post_lvl_result = pre_post_lvl_accuracy_unpviot %>% 
  group_by(study_group, qz_level, variable) %>%
  summarize(smean = mean(value), 
            ssd = sd(value),
            n = n()) %>%
  mutate(se = ssd / sqrt(n),
         lower_ci = lower_ci(smean, se, n),
         upper_ci = upper_ci(smean, se, n))

pre_post_lvl_result
```



```{r}
#
# The paired t-test to measure the significance of the secondary outcomes
# (p-values in Table 3)
#
options(digits=4)
for (type in unique(pre_post_lvl_accuracy_pvt$study_group)) {
  for (qz_lvl in unique(pre_post_lvl_accuracy_pvt$qz_level)) {
    sub_data = pre_post_lvl_accuracy_pvt %>% filter(study_group == type, qz_level == qz_lvl)
    mean_post = sub_data$posttest
    mean_pre = sub_data$pretest
    result = t.test(mean_post, mean_pre, paired = TRUE, alternative = "two.sided", exact = FALSE)
    cat(type, qz_lvl)
    print(result)
    print(result[3])
  }
}


```



# Visualization

```{r}

resp_level = response
resp_level$qz_level = "ALL"
resp_level = rbind(response, resp_level)

pre_post_result_level = resp_level %>%
  group_by(study_group, qz_level, pre_post, user_id) %>%
  summarize(mean.score = mean(correct)) %>%
  group_by(study_group, qz_level, pre_post) %>%
  summarize(smean = mean(mean.score)) %>%
  mutate(qz_level = factor(qz_level, levels=c("ALL","EASY","HARD"), 
                           labels = c("(a)  All", "(b)  Easy", "(c)  Hard"))) 



```

```{r}

plot1 = pre_post_result_level  %>%
  ggplot(aes(x = pre_post, y=smean, group = study_group, color=factor(study_group))) +
  geom_line(size=1) + 
  geom_point() +
  
  theme(axis.title.x=element_blank()) +
  theme(text = element_text(size=15)) +
  ylab("Accuracy") +
  scale_color_manual(name="Intervention", 
                     labels=c(expression(EB), expression(ML[DR]), expression(ML[IR])), 
                     values=c("#999999", "#E69F00", "#56B4E9")) +
  theme(legend.text.align = 0) +
  facet_wrap(~qz_level) 
  

plot1

```

```{r}
ggsave(filename = "accuracy_by_case_complexity.png", width=8, height=4, device="png", dpi=200)
```
